# -*- coding: utf-8 -*-
"""
S&P500 ì¢…ëª© ë°ì´í„° ê¸°ë°˜ ìŒë°”ë‹¥ íŒ¨í„´ ë¶„ì„ (yfinance ìë™ ë‹¤ìš´ë¡œë“œ ë²„ì „)
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import yfinance as yf
import requests
from datetime import datetime
import os
import warnings
import tempfile
from openpyxl import Workbook
from openpyxl.drawing.image import Image
from openpyxl.styles import Alignment, Font
warnings.filterwarnings('ignore')

# í•œê¸€ í°íŠ¸ ì„¤ì •
plt.rcParams['font.family'] = 'Malgun Gothic'
plt.rcParams['axes.unicode_minus'] = False


class ExcelSparklineGenerator:
    """Excel ìŠ¤íŒŒí¬ë¼ì¸ ìƒì„± í´ë˜ìŠ¤"""
    
    def __init__(self):
        pass
    
    def create_sparkline_image(self, data, width=180, height=40, color='#2E86AB'):
        """ìŠ¤íŒŒí¬ë¼ì¸ ì´ë¯¸ì§€ ìƒì„±"""
        data = pd.to_numeric(data, errors='coerce').dropna()
        
        if len(data) < 2:
            return None
        
        # DPI ì„¤ì •
        dpi = 100
        fig_width = width / dpi
        fig_height = height / dpi
        
        # ê·¸ë˜í”„ ìƒì„±
        fig, ax = plt.subplots(figsize=(fig_width, fig_height), dpi=dpi)
        
        # ë©”ì¸ ë¼ì¸ ê·¸ë¦¬ê¸°
        ax.plot(data.values, color=color, linewidth=2, alpha=0.8)
        
        # ìµœê³ ì ê³¼ ìµœì €ì  í‘œì‹œ
        max_idx = data.values.argmax()
        min_idx = data.values.argmin()
        ax.scatter([max_idx], [data.values[max_idx]], color='red', s=15, zorder=5)
        ax.scatter([min_idx], [data.values[min_idx]], color='blue', s=15, zorder=5)
        
        # ì¶• ìˆ¨ê¸°ê¸°
        ax.set_xticks([])
        ax.set_yticks([])
        ax.spines['top'].set_visible(False)
        ax.spines['right'].set_visible(False)
        ax.spines['bottom'].set_visible(False)
        ax.spines['left'].set_visible(False)
        
        # ë°°ê²½ ì„¤ì •
        ax.set_facecolor('white')
        fig.patch.set_facecolor('white')
        
        # ì—¬ë°± ì œê±°
        plt.subplots_adjust(left=0, right=1, top=1, bottom=0)
        
        # ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥
        temp_file = tempfile.NamedTemporaryFile(delete=False, suffix='.png')
        fig.savefig(temp_file.name, dpi=dpi, bbox_inches='tight', 
                   pad_inches=0, facecolor='white', edgecolor='none')
        plt.close(fig)
        
        return temp_file.name


class DoubleBottomAnalyzer:
    """ìŒë°”ë‹¥ íŒ¨í„´ ë¶„ì„ í´ë˜ìŠ¤"""

    def __init__(self):
        self.df_long = None
        self.double_bottom_results = []
        self.stock_info = {}  # ì¢…ëª©ë³„ ì„¹í„° ì •ë³´ ì €ì¥

    def find_local_minima_maxima(self, series, window=5):
        minima_indices, maxima_indices = [], []
        for i in range(window, len(series) - window):
            if series.iloc[i] == series.iloc[i - window:i + window + 1].min():
                minima_indices.append(i)
            if series.iloc[i] == series.iloc[i - window:i + window + 1].max():
                maxima_indices.append(i)
        return minima_indices, maxima_indices

    def find_previous_lowest_bottom(self, data, current_bottom_idx, lookback_days=60):
        if current_bottom_idx < lookback_days:
            return None, None
        previous_data = data.iloc[max(0, current_bottom_idx - lookback_days):current_bottom_idx]
        if len(previous_data) == 0:
            return None, None
        prev_lowest = previous_data['Close'].min()
        prev_lowest_idx = previous_data['Close'].idxmin()
        return prev_lowest, prev_lowest_idx

    def check_sideways_after_bottom(self, data, bottom_idx, days=3, tolerance_pct=0.02):
        if bottom_idx + days >= len(data):
            return False
        after_bottom_data = data.iloc[bottom_idx:bottom_idx + days + 1]
        bottom_price = data.iloc[bottom_idx]['Close']
        max_price = after_bottom_data['Close'].max()
        min_price = after_bottom_data['Close'].min()
        max_deviation = max(abs(max_price - bottom_price), abs(min_price - bottom_price))
        deviation_pct = max_deviation / bottom_price
        return deviation_pct <= tolerance_pct

    def validate_double_bottom_pattern(self, data, first_bottom_idx, second_bottom_idx,
                                       first_bottom_price, second_bottom_price, lookback_days=60):
        prev_lowest, prev_lowest_idx = self.find_previous_lowest_bottom(data, first_bottom_idx, lookback_days)
        first_window = data.iloc[max(0, first_bottom_idx - 10):first_bottom_idx + 10]
        first_local_min = first_window['Close'].min()
        second_window = data.iloc[max(0, second_bottom_idx - 10):second_bottom_idx + 10]
        second_local_min = second_window['Close'].min()
        recent_bottom_sideways = self.check_sideways_after_bottom(data, second_bottom_idx, days=3, tolerance_pct=0.02)

        validation_result = {
            'prev_lowest': prev_lowest,
            'prev_lowest_idx': prev_lowest_idx,
            'first_local_min': first_local_min,
            'second_local_min': second_local_min,
            'recent_bottom_sideways': recent_bottom_sideways,
            'is_valid_double_bottom': False,
            'issues': [],
            'validation_score': 0
        }

        score = 100
        if prev_lowest is not None:
            if first_bottom_price <= prev_lowest:
                validation_result['issues'].append("ì²« ë²ˆì§¸ ë°”ë‹¥ì´ ì´ì „ ìµœì €ê°€ë³´ë‹¤ ë‚®ê±°ë‚˜ ê°™ìŒ")
                score -= 30
            else:
                improvement_pct = (first_bottom_price - prev_lowest) / prev_lowest
                if improvement_pct > 0.05:
                    score += 10

        if first_bottom_price != first_local_min:
            validation_result['issues'].append("ì²« ë²ˆì§¸ ë°”ë‹¥ì´ ì£¼ë³€ ìµœì €ê°€ì™€ ë‹¤ë¦„")
            score -= 20
        if second_bottom_price != second_local_min:
            validation_result['issues'].append("ë‘ ë²ˆì§¸ ë°”ë‹¥ì´ ì£¼ë³€ ìµœì €ê°€ì™€ ë‹¤ë¦„")
            score -= 20

        if not recent_bottom_sideways:
            validation_result['issues'].append("ìµœê·¼ ë°”ë‹¥ ì´í›„ 3ì¼ê°„ íš¡ë³´í•˜ì§€ ì•ŠìŒ")
            score -= 20
        else:
            score += 10

        if len(validation_result['issues']) == 0:
            validation_result['is_valid_double_bottom'] = True
        validation_result['validation_score'] = max(0, score)
        return validation_result

    def calculate_double_bottom_score(self, stock_data,
                                      bottom_tolerance_pct=0.10,
                                      rebound_min_pct=0.05,
                                      breakout_min_pct=0.02,
                                      min_days_between_bottoms=10,
                                      max_days_between_bottoms=120,
                                      lookback_period=120):
        if len(stock_data) < 50:
            return None
        df_recent = stock_data.tail(lookback_period).reset_index(drop=True)
        minima_indices, _ = self.find_local_minima_maxima(df_recent['Close'], window=3)
        if len(minima_indices) < 2:
            return None
        best_score, best_pattern = 0, None

        for i, b1_idx in enumerate(minima_indices[:-1]):
            b1_price = df_recent.loc[b1_idx, 'Close']
            b2_candidates = [idx for idx in minima_indices[i + 1:]
                             if (min_days_between_bottoms <= idx - b1_idx <= max_days_between_bottoms)]
            for b2_idx in b2_candidates:
                b2_price = df_recent.loc[b2_idx, 'Close']
                price_diff_pct = abs(b1_price - b2_price) / min(b1_price, b2_price)
                if price_diff_pct > bottom_tolerance_pct:
                    continue
                if b2_idx - b1_idx <= 1:
                    continue
                peak_slice = df_recent.loc[b1_idx + 1:b2_idx - 1, 'Close']
                if peak_slice.empty:
                    continue
                peak_idx = peak_slice.idxmax()
                peak_price = df_recent.loc[peak_idx, 'Close']
                rebound_pct = (peak_price - b1_price) / b1_price
                if rebound_pct < rebound_min_pct:
                    continue
                current_price = df_recent['Close'].iloc[-1]
                breakout_pct = (current_price - peak_price) / peak_price
                score = 0
                similarity_score = max(0, 30 * (1 - price_diff_pct / bottom_tolerance_pct))
                score += similarity_score
                rebound_score = min(25, 25 * rebound_pct / rebound_min_pct)
                score += rebound_score
                if breakout_pct > 0:
                    breakout_score = min(25, 25 * breakout_pct / breakout_min_pct)
                    score += breakout_score
                else:
                    score += 10
                pattern_completeness = 20 if breakout_pct > breakout_min_pct else 15
                score += pattern_completeness
                validation = self.validate_double_bottom_pattern(df_recent, b1_idx, b2_idx, b1_price, b2_price, 60)
                if validation['is_valid_double_bottom']:
                    score *= 1.2
                else:
                    score *= 0.7
                validation_bonus = min(20, validation['validation_score'] * 0.2)
                score += validation_bonus
                if score > best_score:
                    best_score = score
                    best_pattern = {
                        'b1_idx': b1_idx, 'b2_idx': b2_idx, 'peak_idx': peak_idx,
                        'b1_price': b1_price, 'b2_price': b2_price, 'peak_price': peak_price,
                        'current_price': current_price, 'price_diff_pct': price_diff_pct,
                        'rebound_pct': rebound_pct, 'breakout_pct': breakout_pct,
                        'score': score, 'validation': validation
                    }
        return best_pattern

    def analyze_all_stocks(self):
        print("ğŸ” ëª¨ë“  ì¢…ëª© ìŒë°”ë‹¥ íŒ¨í„´ ë¶„ì„ ì¤‘...")
        results, total_stocks, processed = [], self.df_long['ì¢…ëª©'].nunique(), 0
        for symbol in self.df_long['ì¢…ëª©'].unique():
            stock_data = self.df_long[self.df_long['ì¢…ëª©'] == symbol].copy()
            pattern = self.calculate_double_bottom_score(stock_data)
            if pattern:
                pattern['symbol'] = symbol
                results.append(pattern)
                print(f"âœ… {symbol}: ì ìˆ˜ {pattern['score']:.1f}")
            processed += 1
            if processed % 50 == 0:
                print(f"ì§„í–‰ë¥ : {processed}/{total_stocks} ({processed / total_stocks * 100:.1f}%)")
        self.double_bottom_results = sorted(results, key=lambda x: x['score'], reverse=True)
        print(f"\nğŸ“ˆ ë¶„ì„ ì™„ë£Œ: {len(self.double_bottom_results)}ê°œ ì¢…ëª©ì—ì„œ ìŒë°”ë‹¥ íŒ¨í„´ ë°œê²¬")

    def get_valid_double_bottom_results(self):
        # ëª¨ë“  ìŒë°”ë‹¥ íŒ¨í„´ ê²°ê³¼ ë°˜í™˜ (ìœ íš¨ì„± ê²€ì‚¬ ë¬´ì‹œ)
        return self.double_bottom_results

    def save_valid_results_to_csv(self, filename='sp500_valid_double_bottom.csv'):
        valid_results = self.get_valid_double_bottom_results()
        if not valid_results:
            print("ì €ì¥í•  ìœ íš¨í•œ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return
        output_dir = 'two_bottom'
        os.makedirs(output_dir, exist_ok=True)
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        filepath = os.path.join(output_dir, f"{filename.split('.')[0]}_{timestamp}.csv")
        results_data = []
        for result in valid_results:
            symbol = result['symbol']
            stock_info = self.stock_info.get(symbol, {})
            results_data.append({
                'ì¢…ëª©': symbol,
                'ì²«ë²ˆì§¸ë°”ë‹¥': result['b1_price'],
                'ë‘ë²ˆì§¸ë°”ë‹¥': result['b2_price'],
                'ë„¥ë¼ì¸': result['peak_price'],
                'í˜„ì¬ê°€': result['current_price'],
                'ë°”ë‹¥ì°¨ì´(%)': round(result['price_diff_pct'] * 100, 2),
                'ë°˜ë“±ë¥ (%)': round(result['rebound_pct'] * 100, 2),
                'ëŒíŒŒë¥ (%)': round(result['breakout_pct'] * 100, 2),
                'ì„¹í„°': stock_info.get('ì„¹í„°', 'N/A')
            })
        pd.DataFrame(results_data).to_csv(filepath, index=False, encoding='utf-8-sig')
        print(f"âœ… ê²°ê³¼ CSV ì €ì¥ ì™„ë£Œ: {filepath}")
        
        # ìŠ¤íŒŒí¬ë¼ì¸ì´ í¬í•¨ëœ Excel íŒŒì¼ë„ ìƒì„±
        self.save_results_with_sparklines(valid_results, filename, timestamp)

    def save_results_with_sparklines(self, valid_results, filename, timestamp):
        """ìŠ¤íŒŒí¬ë¼ì¸ì´ í¬í•¨ëœ Excel íŒŒì¼ ì €ì¥"""
        if not valid_results:
            return
            
        print("ğŸ“Š ìŠ¤íŒŒí¬ë¼ì¸ì´ í¬í•¨ëœ Excel íŒŒì¼ ìƒì„± ì¤‘...")
        
        output_dir = 'two_bottom'
        excel_filepath = os.path.join(output_dir, f"{filename.split('.')[0]}_with_sparklines_{timestamp}.xlsx")
        
        # ì›Œí¬ë¶ ìƒì„±
        wb = Workbook()
        ws = wb.active
        ws.title = "S&P500 ìŒë°”ë‹¥ íŒ¨í„´"
        
        # í—¤ë” ì„¤ì •
        headers = ['ì¢…ëª©', 'ìŠ¤íŒŒí¬ë¼ì¸', 'ì²«ë²ˆì§¸ë°”ë‹¥', 'ë‘ë²ˆì§¸ë°”ë‹¥', 'ë„¥ë¼ì¸', 'í˜„ì¬ê°€', 
                  'ë°”ë‹¥ì°¨ì´(%)', 'ë°˜ë“±ë¥ (%)', 'ëŒíŒŒë¥ (%)', 'ì„¹í„°', 'ì ìˆ˜']
        
        for col, header in enumerate(headers, 1):
            cell = ws.cell(row=1, column=col, value=header)
            cell.font = Font(bold=True)
            cell.alignment = Alignment(horizontal='center')
        
        # ì»¬ëŸ¼ ë„ˆë¹„ ì„¤ì •
        ws.column_dimensions['A'].width = 15  # ì¢…ëª©ëª…
        ws.column_dimensions['B'].width = 20  # ìŠ¤íŒŒí¬ë¼ì¸
        ws.column_dimensions['C'].width = 12  # ì²«ë²ˆì§¸ë°”ë‹¥
        ws.column_dimensions['D'].width = 12  # ë‘ë²ˆì§¸ë°”ë‹¥
        ws.column_dimensions['E'].width = 12  # ë„¥ë¼ì¸
        ws.column_dimensions['F'].width = 12  # í˜„ì¬ê°€
        ws.column_dimensions['G'].width = 12  # ë°”ë‹¥ì°¨ì´
        ws.column_dimensions['H'].width = 12  # ë°˜ë“±ë¥ 
        ws.column_dimensions['I'].width = 12  # ëŒíŒŒë¥ 
        ws.column_dimensions['J'].width = 15  # ì„¹í„°
        ws.column_dimensions['K'].width = 10  # ì ìˆ˜
        
        # í–‰ ë†’ì´ ì„¤ì •
        ws.row_dimensions[1].height = 30  # í—¤ë” í–‰
        for row in range(2, len(valid_results) + 2):
            ws.row_dimensions[row].height = 50  # ìŠ¤íŒŒí¬ë¼ì¸ì„ ìœ„í•œ ë†’ì´
        
        # ìŠ¤íŒŒí¬ë¼ì¸ ìƒì„±ê¸° ì´ˆê¸°í™”
        sparkline_gen = ExcelSparklineGenerator()
        temp_files = []  # ì„ì‹œ íŒŒì¼ ì¶”ì ìš©
        
        # ê° ê²°ê³¼ì— ëŒ€í•´ ë°ì´í„° ì¶”ê°€
        for row_idx, result in enumerate(valid_results, 2):
            try:
                symbol = result['symbol']
                stock_info = self.stock_info.get(symbol, {})
                
                # ì¢…ëª©ëª…
                ws.cell(row=row_idx, column=1, value=symbol)
                
                # í•´ë‹¹ ì¢…ëª©ì˜ ì£¼ê°€ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
                stock_data = self.df_long[self.df_long['ì¢…ëª©'] == symbol].copy()
                if not stock_data.empty:
                    # ìµœê·¼ 6ê°œì›” ë°ì´í„°ë¡œ ìŠ¤íŒŒí¬ë¼ì¸ ìƒì„±
                    recent_data = stock_data.tail(120)  # ì•½ 6ê°œì›”
                    price_data = recent_data['Close'].values
                    
                    # ìŠ¤íŒŒí¬ë¼ì¸ ì´ë¯¸ì§€ ìƒì„±
                    if len(price_data) > 1:
                        temp_img_path = sparkline_gen.create_sparkline_image(
                            pd.Series(price_data), width=180, height=40
                        )
                        if temp_img_path:
                            temp_files.append(temp_img_path)
                            
                            # Excelì— ì´ë¯¸ì§€ ì‚½ì…
                            img = Image(temp_img_path)
                            img.width = 180
                            img.height = 40
                            ws.add_image(img, f'B{row_idx}')
                
                # ë‚˜ë¨¸ì§€ ë°ì´í„° ì¶”ê°€
                ws.cell(row=row_idx, column=3, value=round(result['b1_price'], 2))
                ws.cell(row=row_idx, column=4, value=round(result['b2_price'], 2))
                ws.cell(row=row_idx, column=5, value=round(result['peak_price'], 2))
                ws.cell(row=row_idx, column=6, value=round(result['current_price'], 2))
                ws.cell(row=row_idx, column=7, value=round(result['price_diff_pct'] * 100, 2))
                ws.cell(row=row_idx, column=8, value=round(result['rebound_pct'] * 100, 2))
                ws.cell(row=row_idx, column=9, value=round(result['breakout_pct'] * 100, 2))
                ws.cell(row=row_idx, column=10, value=stock_info.get('ì„¹í„°', 'N/A'))
                ws.cell(row=row_idx, column=11, value=round(result['score'], 1))
                
                # ìˆ«ì ì…€ ì •ë ¬
                for col in range(3, 12):
                    ws.cell(row=row_idx, column=col).alignment = Alignment(horizontal='center')
                
                if row_idx % 10 == 0:
                    print(f"ì§„í–‰ë¥ : {row_idx-1}/{len(valid_results)} ì¢…ëª© ì™„ë£Œ")
                    
            except Exception as e:
                print(f"ì¢…ëª© '{symbol}' ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
                continue
        
        # Excel íŒŒì¼ ì €ì¥
        wb.save(excel_filepath)
        
        # ì„ì‹œ íŒŒì¼ë“¤ ì‚­ì œ
        for temp_file in temp_files:
            try:
                os.unlink(temp_file)
            except:
                pass
        
        print(f"âœ… ìŠ¤íŒŒí¬ë¼ì¸ Excel ì €ì¥ ì™„ë£Œ: {excel_filepath}")
        
        # íŒŒì¼ ìë™ ì—´ê¸°
        try:
            import subprocess
            import platform
            if platform.system() == 'Windows':
                os.startfile(excel_filepath)
            elif platform.system() == 'Darwin':  # macOS
                subprocess.run(['open', excel_filepath])
            else:  # Linux
                subprocess.run(['xdg-open', excel_filepath])
            print("âœ… Excel íŒŒì¼ì´ ìë™ìœ¼ë¡œ ì—´ë ¸ìŠµë‹ˆë‹¤.")
        except Exception as e:
            print(f"íŒŒì¼ ìë™ ì—´ê¸° ì‹¤íŒ¨: {e}")


def get_sp500_tickers():
    """S&P 500 ì¢…ëª© ë¦¬ìŠ¤íŠ¸ë¥¼ ê°€ì ¸ì˜¤ëŠ” í•¨ìˆ˜ (ì—¬ëŸ¬ ë°©ë²• ì‹œë„)"""
    print("ğŸ“‹ S&P 500 ì¢…ëª© ë¦¬ìŠ¤íŠ¸ ê°€ì ¸ì˜¤ëŠ” ì¤‘...")
    
    # ë°©ë²• 1: Wikipediaì—ì„œ S&P 500 ì¢…ëª© ë¦¬ìŠ¤íŠ¸ ê°€ì ¸ì˜¤ê¸°
    try:
        print("ë°©ë²• 1: Wikipediaì—ì„œ S&P 500 ì¢…ëª© ë¦¬ìŠ¤íŠ¸ ê°€ì ¸ì˜¤ê¸° ì‹œë„...")
        import requests
        from bs4 import BeautifulSoup
        
        url = "https://en.wikipedia.org/wiki/List_of_S%26P_500_companies"
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
        }
        
        response = requests.get(url, headers=headers, timeout=30)
        response.raise_for_status()
        
        soup = BeautifulSoup(response.content, 'html.parser')
        table = soup.find('table', {'id': 'constituents'})
        
        if table:
            tickers = []
            sectors = []
            names = []
            
            rows = table.find_all('tr')[1:]  # í—¤ë” ì œì™¸
            for row in rows:
                cells = row.find_all('td')
                if len(cells) >= 4:
                    ticker = cells[0].text.strip()
                    name = cells[1].text.strip()
                    sector = cells[2].text.strip()
                    
                    # íŠ¹ìˆ˜ ë¬¸ì ì œê±° ë° ìœ íš¨í•œ í‹°ì»¤ë§Œ ì¶”ê°€
                    if ticker and not ticker.startswith('(') and len(ticker) <= 5:
                        tickers.append(ticker)
                        sectors.append(sector)
                        names.append(name)
            
            if len(tickers) > 400:  # ì¶©ë¶„í•œ ì¢…ëª© ìˆ˜ í™•ì¸
                print(f"âœ… Wikipediaì—ì„œ {len(tickers)}ê°œ S&P 500 ì¢…ëª© ë¦¬ìŠ¤íŠ¸ ê°€ì ¸ì˜¤ê¸° ì„±ê³µ")
                print(f"ğŸš€ ì „ì²´ {len(tickers)}ê°œ ì¢…ëª©ìœ¼ë¡œ ìŒë°”ë‹¥ íŒ¨í„´ ë¶„ì„ì„ ì‹œì‘í•©ë‹ˆë‹¤!")
                
                # ë°ì´í„°í”„ë ˆì„ ìƒì„±
                info_data = []
                for i, ticker in enumerate(tickers):
                    info_data.append({
                        'Symbol': ticker,
                        'Security': names[i] if i < len(names) else ticker,
                        'GICS Sector': sectors[i] if i < len(sectors) else 'Unknown'
                    })
                
                info_df = pd.DataFrame(info_data)
                return tickers, info_df
            else:
                raise Exception(f"ì¢…ëª© ìˆ˜ ë¶€ì¡±: {len(tickers)}ê°œ")
        else:
            raise Exception("S&P 500 í…Œì´ë¸”ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ")
            
    except Exception as e:
        print(f"âŒ Wikipedia ë°©ë²• ì‹¤íŒ¨: {e}")
    
    # ë°©ë²• 2: yfinanceë¥¼ ì‚¬ìš©í•˜ì—¬ S&P 500 ETFì—ì„œ êµ¬ì„±ì¢…ëª© ê°€ì ¸ì˜¤ê¸°
    try:
        print("ë°©ë²• 2: yfinanceë¥¼ í†µí•œ S&P 500 êµ¬ì„±ì¢…ëª© ê°€ì ¸ì˜¤ê¸° ì‹œë„...")
        sp500 = yf.Ticker("^GSPC")
        # S&P 500 ETF (SPY)ì˜ êµ¬ì„±ì¢…ëª© ì •ë³´ ê°€ì ¸ì˜¤ê¸°
        spy = yf.Ticker("SPY")
        # ì´ ë°©ë²•ì€ ì œí•œì ì´ë¯€ë¡œ ë‹¤ë¥¸ ë°©ë²•ë„ ì‹œë„
        
        # ë°©ë²• 3: ì§ì ‘ S&P 500 ì¢…ëª© ë¦¬ìŠ¤íŠ¸ ì‚¬ìš© (ì£¼ìš” ì¢…ëª©ë“¤ - í…ŒìŠ¤íŠ¸ìš©ìœ¼ë¡œ ì†Œìˆ˜ë§Œ)
        print("ë°©ë²• 3: ì£¼ìš” S&P 500 ì¢…ëª© ë¦¬ìŠ¤íŠ¸ ì‚¬ìš©...")
        major_sp500_tickers = [
            'AAPL', 'MSFT', 'GOOGL', 'AMZN', 'NVDA', 'META', 'TSLA', 'JPM', 'JNJ', 'V',
            'PG', 'HD', 'MA', 'DIS', 'PYPL', 'ADBE', 'NFLX', 'CRM', 'CMCSA', 'PFE',
            'ABT', 'TMO', 'COST', 'PEP', 'AVGO', 'TXN', 'QCOM', 'ACN', 'NKE', 'DHR'
        ]
        
        # ì„¹í„° ì •ë³´ë¥¼ ìœ„í•œ ê¸°ë³¸ ë§¤í•‘
        sector_mapping = {
            'AAPL': 'Technology', 'MSFT': 'Technology', 'GOOGL': 'Communication Services',
            'AMZN': 'Consumer Discretionary', 'NVDA': 'Technology', 'META': 'Communication Services',
            'TSLA': 'Consumer Discretionary', 'BRK-B': 'Financials', 'UNH': 'Health Care',
            'JNJ': 'Health Care', 'V': 'Financials', 'PG': 'Consumer Staples',
            'JPM': 'Financials', 'HD': 'Consumer Discretionary', 'MA': 'Financials',
            'DIS': 'Communication Services', 'PYPL': 'Financials', 'ADBE': 'Technology',
            'NFLX': 'Communication Services', 'CRM': 'Technology', 'CMCSA': 'Communication Services',
            'PFE': 'Health Care', 'ABT': 'Health Care', 'TMO': 'Health Care',
            'COST': 'Consumer Staples', 'PEP': 'Consumer Staples', 'AVGO': 'Technology',
            'TXN': 'Technology', 'QCOM': 'Technology', 'ACN': 'Technology',
            'NKE': 'Consumer Discretionary', 'DHR': 'Health Care', 'VZ': 'Communication Services',
            'ADP': 'Technology', 'T': 'Communication Services', 'NEE': 'Utilities',
            'LIN': 'Materials', 'ABBV': 'Health Care', 'ORCL': 'Technology',
            'MRK': 'Health Care', 'UNP': 'Industrials', 'PM': 'Consumer Staples',
            'RTX': 'Industrials', 'HON': 'Industrials', 'SPGI': 'Financials',
            'LOW': 'Consumer Discretionary', 'IBM': 'Technology', 'AMD': 'Technology',
            'INTU': 'Technology', 'BKNG': 'Consumer Discretionary', 'AMAT': 'Technology',
            'GE': 'Industrials', 'CAT': 'Industrials', 'DE': 'Industrials',
            'AXP': 'Financials', 'CVX': 'Energy', 'GS': 'Financials',
            'WMT': 'Consumer Staples', 'KO': 'Consumer Staples'
        }
        
        # ë°ì´í„°í”„ë ˆì„ ìƒì„±
        info_data = []
        for ticker in major_sp500_tickers:
            info_data.append({
                'Symbol': ticker,
                'Security': ticker,  # ê°„ë‹¨íˆ ì‹¬ë³¼ë¡œ ì„¤ì •
                'GICS Sector': sector_mapping.get(ticker, 'Unknown')
            })
        
        info_df = pd.DataFrame(info_data)
        tickers = major_sp500_tickers
        
        print(f"âœ… {len(tickers)}ê°œ S&P 500 ì¢…ëª© ë¦¬ìŠ¤íŠ¸ ì¤€ë¹„ ì™„ë£Œ")
        return tickers, info_df
        
    except Exception as e:
        print(f"âŒ S&P 500 ì¢…ëª© ë¦¬ìŠ¤íŠ¸ ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨: {e}")
        # ë°©ë²• 3: ìµœì†Œí•œì˜ ì£¼ìš” ì¢…ëª©ë“¤ë¡œ í´ë°±
        print("ë°©ë²• 3: ìµœì†Œí•œì˜ ì£¼ìš” ì¢…ëª©ìœ¼ë¡œ í´ë°±...")
        fallback_tickers = ['AAPL', 'MSFT', 'GOOGL', 'AMZN', 'NVDA', 'META', 'TSLA', 'JPM', 'JNJ', 'V']
        fallback_info = pd.DataFrame({
            'Symbol': fallback_tickers,
            'Security': fallback_tickers,
            'GICS Sector': ['Technology'] * 5 + ['Communication Services', 'Consumer Discretionary', 'Financials', 'Health Care', 'Financials']
        })
        return fallback_tickers, fallback_info


def download_stock_data_direct(ticker, period="1y", max_retries=3):
    """requestsë¥¼ ì‚¬ìš©í•˜ì—¬ ì§ì ‘ Yahoo Finance API í˜¸ì¶œ (ì¬ì‹œë„ ë©”ì»¤ë‹ˆì¦˜ í¬í•¨)"""
    import time
    import json
    from datetime import datetime, timedelta
    
    for attempt in range(max_retries):
        try:
            # ê¸°ê°„ ì„¤ì •
            if period == "1y":
                days = 365
            elif period == "6mo":
                days = 180
            elif period == "3mo":
                days = 90
            else:
                days = 365
                
            end_date = datetime.now()
            start_date = end_date - timedelta(days=days)
            
            # Yahoo Finance API URL
            url = f"https://query1.finance.yahoo.com/v8/finance/chart/{ticker}"
            params = {
                'period1': int(start_date.timestamp()),
                'period2': int(end_date.timestamp()),
                'interval': '1d',
                'includePrePost': 'true',
                'events': 'div,split'
            }
            
            headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
                'Accept': 'application/json',
                'Accept-Language': 'en-US,en;q=0.9',
                'Accept-Encoding': 'gzip, deflate, br',
                'Connection': 'keep-alive',
                'Upgrade-Insecure-Requests': '1'
            }
            
            response = requests.get(url, params=params, headers=headers, timeout=30)
            response.raise_for_status()
            
            # JSON ì‘ë‹µ ê²€ì¦
            if not response.text.strip():
                raise ValueError("ë¹ˆ ì‘ë‹µ")
                
            data = response.json()
            
            if 'chart' not in data or not data['chart']['result']:
                raise ValueError("ìœ íš¨í•˜ì§€ ì•Šì€ ì°¨íŠ¸ ë°ì´í„°")
                
            result = data['chart']['result'][0]
            if 'timestamp' not in result or 'indicators' not in result:
                raise ValueError("í•„ìˆ˜ ë°ì´í„° í•„ë“œ ëˆ„ë½")
                
            timestamps = result['timestamp']
            quotes = result['indicators']['quote'][0]
            
            if not timestamps or 'close' not in quotes:
                raise ValueError("ê°€ê²© ë°ì´í„° ì—†ìŒ")
            
            # ë°ì´í„°í”„ë ˆì„ ìƒì„±
            df_data = []
            for i, timestamp in enumerate(timestamps):
                if i < len(quotes['close']) and quotes['close'][i] is not None:
                    df_data.append({
                        'ë‚ ì§œ': datetime.fromtimestamp(timestamp).strftime('%Y-%m-%d'),
                        'Close': quotes['close'][i],
                        'ì¢…ëª©': ticker
                    })
            
            if not df_data:
                raise ValueError("ìœ íš¨í•œ ê°€ê²© ë°ì´í„° ì—†ìŒ")
                
            df = pd.DataFrame(df_data)
            df['ë‚ ì§œ'] = pd.to_datetime(df['ë‚ ì§œ'])
            df = df.dropna()
            
            if len(df) < 10:  # ìµœì†Œ ë°ì´í„° í¬ì¸íŠ¸ í™•ì¸
                raise ValueError("ë°ì´í„° í¬ì¸íŠ¸ ë¶€ì¡±")
                
            return df
            
        except Exception as e:
            if attempt < max_retries - 1:
                wait_time = (attempt + 1) * 2  # ì§€ìˆ˜ ë°±ì˜¤í”„
                print(f"âš ï¸ {ticker} ì‹œë„ {attempt + 1}/{max_retries} ì‹¤íŒ¨: {e}, {wait_time}ì´ˆ í›„ ì¬ì‹œë„...")
                time.sleep(wait_time)
            else:
                print(f"âŒ {ticker} ì§ì ‘ ë‹¤ìš´ë¡œë“œ ìµœì¢… ì‹¤íŒ¨: {e}")
                return None


def download_sp500_data(period="1y"):
    """S&P 500 ì¢…ëª© ë°ì´í„°ë¥¼ ë‹¤ìš´ë¡œë“œí•˜ëŠ” í•¨ìˆ˜"""
    tickers, info_df = get_sp500_tickers()
    print(f"ğŸ“Š S&P500 ì¢…ëª© {len(tickers)}ê°œ ë‹¤ìš´ë¡œë“œ ì¤‘... (ê¸°ê°„={period})")
    
    # yfinance ë°°ì¹˜ ë‹¤ìš´ë¡œë“œ ì‹œë„ (ë” ì•ˆì „í•œ ë°©ì‹)
    try:
        print("yfinanceë¡œ ë°°ì¹˜ ë‹¤ìš´ë¡œë“œ ì‹œë„...")
        # ì‘ì€ ë°°ì¹˜ë¡œ ë‚˜ëˆ„ì–´ì„œ ë‹¤ìš´ë¡œë“œ ì‹œë„
        batch_size = 10
        all_data = []
        
        for i in range(0, len(tickers), batch_size):
            batch_tickers = tickers[i:i+batch_size]
            print(f"ë°°ì¹˜ {i//batch_size + 1}/{(len(tickers)-1)//batch_size + 1}: {batch_tickers}")
            
            try:
                data = yf.download(batch_tickers, period=period, interval="1d", 
                                 group_by='ticker', progress=False, threads=True)
                
                if not data.empty:
                    # ë°ì´í„° ì²˜ë¦¬
                    if len(batch_tickers) == 1:
                        data = data.reset_index()
                        data.columns = ['ë‚ ì§œ', 'Open', 'High', 'Low', 'Close', 'Volume']
                        df_batch = data[['ë‚ ì§œ', 'Close']].copy()
                        df_batch['ì¢…ëª©'] = batch_tickers[0]
                    else:
                        if 'Close' in data.columns:
                            df = data.reset_index().rename(columns={'Date': 'ë‚ ì§œ'})
                            df_batch = df.melt(id_vars=['ë‚ ì§œ'], var_name='ì¢…ëª©', value_name='Close')
                        else:
                            df = data['Close'].reset_index().rename(columns={'Date': 'ë‚ ì§œ'})
                            df_batch = df.melt(id_vars=['ë‚ ì§œ'], var_name='ì¢…ëª©', value_name='Close')
                    
                    df_batch = df_batch.dropna()
                    all_data.append(df_batch)
                    print(f"âœ… ë°°ì¹˜ {i//batch_size + 1} ì™„ë£Œ: {len(df_batch)}í–‰")
                else:
                    print(f"âŒ ë°°ì¹˜ {i//batch_size + 1} ë°ì´í„° ì—†ìŒ")
                    
            except Exception as batch_error:
                print(f"âŒ ë°°ì¹˜ {i//batch_size + 1} ì‹¤íŒ¨: {batch_error}")
                # ê°œë³„ ì¢…ëª©ìœ¼ë¡œ ì¬ì‹œë„
                for ticker in batch_tickers:
                    try:
                        df = download_stock_data_direct(ticker, period)
                        if df is not None and not df.empty:
                            all_data.append(df)
                            print(f"âœ… {ticker} ê°œë³„ ë‹¤ìš´ë¡œë“œ ì„±ê³µ")
                    except:
                        print(f"âŒ {ticker} ê°œë³„ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨")
                        continue
                
                # ìš”ì²­ ê°„ê²© ì¡°ì ˆ
                import time
                time.sleep(1)
        
        if all_data:
            df_long = pd.concat(all_data, ignore_index=True)
            df_long = df_long.sort_values(['ì¢…ëª©', 'ë‚ ì§œ']).reset_index(drop=True)
            print(f"âœ… yfinance ë°°ì¹˜ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ: {len(df_long)}í–‰, {df_long['ì¢…ëª©'].nunique()}ê°œ ì¢…ëª©")
            return df_long, info_df
        else:
            raise Exception("ëª¨ë“  ë°°ì¹˜ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨")
            
    except Exception as e:
        print(f"âŒ yfinance ë°°ì¹˜ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {e}")
        print("ì§ì ‘ API í˜¸ì¶œë¡œ ì¬ì‹œë„...")
    
    # ì§ì ‘ API í˜¸ì¶œë¡œ ì¬ì‹œë„
    successful_data = []
    for i, ticker in enumerate(tickers):
        try:
            print(f"ì§„í–‰ë¥ : {i+1}/{len(tickers)} - {ticker} ë‹¤ìš´ë¡œë“œ ì¤‘...")
            df = download_stock_data_direct(ticker, period)
            if df is not None and not df.empty:
                successful_data.append(df)
                print(f"âœ… {ticker} ë‹¤ìš´ë¡œë“œ ì„±ê³µ")
            else:
                print(f"âŒ {ticker} ë°ì´í„° ì—†ìŒ")
        except Exception as ticker_error:
            print(f"âŒ {ticker} ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {ticker_error}")
            continue
        
        # ì§„í–‰ë¥  í‘œì‹œ ë° ìš”ì²­ ê°„ê²© ì¡°ì ˆ
        if (i + 1) % 10 == 0:
            print(f"ì§„í–‰ë¥ : {i+1}/{len(tickers)} ({((i+1)/len(tickers)*100):.1f}%)")
            import time
            time.sleep(0.5)  # ìš”ì²­ ê°„ê²© ì¡°ì ˆ
    
    if successful_data:
        df_long = pd.concat(successful_data, ignore_index=True)
        df_long = df_long.sort_values(['ì¢…ëª©', 'ë‚ ì§œ']).reset_index(drop=True)
        print(f"âœ… ì§ì ‘ API ë‹¤ìš´ë¡œë“œ ì™„ë£Œ: {len(df_long)}í–‰, {df_long['ì¢…ëª©'].nunique()}ê°œ ì¢…ëª©")
        return df_long, info_df
    else:
        print("âŒ ëª¨ë“  ì¢…ëª© ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨")
        return None, info_df


def load_korean_stock_data():
    """í•œêµ­ ì£¼ì‹ ë°ì´í„°ë¥¼ ë¡œë“œí•˜ëŠ” í•¨ìˆ˜"""
    print("ğŸ“‹ í•œêµ­ ì£¼ì‹ ë°ì´í„° ë¡œë“œ ì¤‘...")
    
    # ê¸°ì¡´ í•œêµ­ ì£¼ì‹ ë°ì´í„° íŒŒì¼ ê²½ë¡œë“¤
    data_files = [
        "../ì½”ìŠ¤í”¼6ê°œì›”ì¢…ê°€_20250908_035947.csv",
        "../two_bottom/ì½”ìŠ¤í”¼6ê°œì›”ì¢…ê°€_with_sector_20250910_015609.csv"
    ]
    
    for file_path in data_files:
        try:
            if os.path.exists(file_path):
                print(f"ğŸ“Š {file_path} íŒŒì¼ ë¡œë“œ ì¤‘...")
                df = pd.read_csv(file_path, encoding='utf-8-sig')
                
                # ë‚ ì§œ ì»¬ëŸ¼ ì°¾ê¸°
                date_cols = [col for col in df.columns if col.startswith('2025-')]
                if not date_cols:
                    print(f"âŒ {file_path}ì—ì„œ ë‚ ì§œ ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                    continue
                
                # ë°ì´í„° ë³€í™˜ (wide to long format)
                df_long = df.melt(id_vars=['ì¢…ëª©'], value_vars=date_cols, var_name='ë‚ ì§œ', value_name='Close')
                df_long = df_long.dropna().sort_values(['ì¢…ëª©', 'ë‚ ì§œ']).reset_index(drop=True)
                
                # ë‚ ì§œ í˜•ì‹ ë³€í™˜
                df_long['ë‚ ì§œ'] = pd.to_datetime(df_long['ë‚ ì§œ'])
                df_long['Close'] = pd.to_numeric(df_long['Close'], errors='coerce')
                df_long = df_long.dropna()
                
                print(f"âœ… í•œêµ­ ì£¼ì‹ ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {len(df_long)}í–‰, {df_long['ì¢…ëª©'].nunique()}ê°œ ì¢…ëª©")
                return df_long, None
                
        except Exception as e:
            print(f"âŒ {file_path} ë¡œë“œ ì‹¤íŒ¨: {e}")
            continue
    
    print("âŒ ëª¨ë“  í•œêµ­ ì£¼ì‹ ë°ì´í„° íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨")
    return None, None


def main():
    print("ğŸš€ S&P 500 ìŒë°”ë‹¥ íŒ¨í„´ ë¶„ì„ ì‹œì‘")
    print("=" * 60)
    
    try:
        # S&P 500 ë°ì´í„° ë‹¤ìš´ë¡œë“œ
        print("S&P 500 ë°ì´í„° ë‹¤ìš´ë¡œë“œ ì¤‘...")
        df_long, info_df = download_sp500_data(period="1y")
        
        # S&P 500 ë°ì´í„°ê°€ ì—†ìœ¼ë©´ í•œêµ­ ì£¼ì‹ ë°ì´í„°ë¡œ í´ë°±
        if df_long is None or df_long.empty:
            print("S&P 500 ë°ì´í„°ë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ì–´ í•œêµ­ ì£¼ì‹ ë°ì´í„°ë¡œ í´ë°±í•©ë‹ˆë‹¤...")
            df_long, info_df = load_korean_stock_data()
        
        if df_long is None or df_long.empty:
            print("âŒ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ì–´ ë¶„ì„ì„ ì¤‘ë‹¨í•©ë‹ˆë‹¤.")
            return
            
        print(f"âœ… ë°ì´í„° ì¤€ë¹„ ì™„ë£Œ: {len(df_long)}í–‰, {df_long['ì¢…ëª©'].nunique()}ê°œ ì¢…ëª©")
        
        analyzer = DoubleBottomAnalyzer()
        analyzer.df_long = df_long
        
        # ì„¹í„° ì •ë³´ ì„¤ì •
        if info_df is not None:
            analyzer.stock_info = {row['Symbol']: {'ì„¹í„°': row['GICS Sector']} for _, row in info_df.iterrows()}
        else:
            # ê¸°ë³¸ ì„¹í„° ì •ë³´ ì„¤ì •
            sectors = ['Technology', 'Healthcare', 'Finance', 'Consumer', 'Industrial', 'Energy', 'Materials', 'Utilities']
            analyzer.stock_info = {symbol: {'ì„¹í„°': sectors[i % len(sectors)]} 
                                 for i, symbol in enumerate(df_long['ì¢…ëª©'].unique())}
        
        print("\nğŸ” ìŒë°”ë‹¥ íŒ¨í„´ ë¶„ì„ ì‹œì‘...")
        analyzer.analyze_all_stocks()
        
        print("\nğŸ’¾ ê²°ê³¼ ì €ì¥ ì¤‘...")
        analyzer.save_valid_results_to_csv()
        
        print("\nğŸ‰ S&P 500 ìŒë°”ë‹¥ íŒ¨í„´ ë¶„ì„ ì™„ë£Œ!")
        
    except Exception as e:
        print(f"âŒ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        print("í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")


if __name__ == '__main__':
    main()
